{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87404224-b84b-409f-8683-c4a243d29722",
   "metadata": {},
   "source": [
    "# Translating a Jupyter book about Bio-image Analsis\n",
    "In this notebook we will translate an existing Jupyter book about Bio-image Analsis from English to another language using a large language model. We use Claude 3.5 Sonnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752e974d-9aaf-44aa-80fb-01a042cf5774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.30.1', '0.29.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "import openai\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "openai.__version__, anthropic.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d3a85-c367-41f8-94dd-87e0b4187740",
   "metadata": {},
   "source": [
    "## Defining the content of the book\n",
    "First we specify the source content of the book and the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d422e570-2735-4153-8c2d-90cd73bee990",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../BioImageAnalysisNotebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2375a5-d453-4c58-9b31-9baf19914e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_language = \"German\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07f0b9-9eda-47c2-9e1b-0873930ec5b0",
   "metadata": {},
   "source": [
    "We will also specify the location where to store the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea1686b-9098-429a-b216-121a3f46f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"\"\n",
    "repository_url = \"https://github.com/generated-books/bio-bildanalyse-notebooks\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef14a82-c1ac-4367-a83f-067923eae779",
   "metadata": {},
   "source": [
    "We will use this language model to generate the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e3b22c-f57c-41c1-8a13-8049e23b3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6903cd45-0b6b-4090-8597-cc4f644cae38",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Here we create some helper functions for prompting and for file format handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e686a0f1-9561-426a-b5b8-d222f7966109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_chatGPT(message:str, model=\"gpt-4o-2024-05-13\"):\n",
    "    \"\"\"\n",
    "    A prompt helper function that sends a message to openAI\n",
    "    and returns only the text response.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import openai\n",
    "    \n",
    "    # convert message in the right format if necessary\n",
    "    if isinstance(message, str):\n",
    "        message = [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "    # setup connection to the LLM\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    # submit prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=message\n",
    "    )\n",
    "    \n",
    "    # extract answer\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea088a7-f187-4c4e-a269-833e14a957d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_claude(message:str, model=\"claude-3-5-sonnet-20240620\"):\n",
    "    \"\"\"\n",
    "    A prompt helper function that sends a message to anthropic\n",
    "    and returns only the text response.\n",
    "\n",
    "    Example models: claude-3-5-sonnet-20240620 or claude-3-opus-20240229\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from anthropic import Anthropic\n",
    "    \n",
    "    # convert message in the right format if necessary\n",
    "    if isinstance(message, str):\n",
    "        message = [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "    # setup connection to the LLM\n",
    "    client = Anthropic()\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        max_tokens=4096,\n",
    "        messages=message,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    # extract answer\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721c3126-67a5-4a65-8bfb-c054bd4dd153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"gpt\" in model:\n",
    "    prompt = partial(prompt_gpt, model=model)\n",
    "else:\n",
    "    prompt = partial(prompt_claude, model=model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a137f79a-287c-4283-8e66-53c8863cdc86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_with_memory(message:str):\n",
    "    \"\"\"\n",
    "    This function allows to use an LLMs in a chat-mode. \n",
    "    The LLM is equipped with some memory, \n",
    "    so that we can refer back for former conversation steps.\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert message in the right format and store it in memory\n",
    "    question = {\"role\": \"user\", \"content\": message}\n",
    "    chat_history.append(question)\n",
    "    \n",
    "    # receive answer\n",
    "    response = prompt(chat_history)\n",
    "    \n",
    "    # convert answer in the right format and store it in memory\n",
    "    answer = {\"role\": \"assistant\", \"content\": response}\n",
    "    chat_history.append(answer)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c8b27a-77f0-431d-a68c-ee4b19f647b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_json(test_string):\n",
    "    \"\"\"This function returns if a string is formatted json.\"\"\"\n",
    "    import json\n",
    "    try:\n",
    "        json.loads(test_string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def ensure_json(notebook):\n",
    "    \"\"\"This function makes sure that the passed notebook is indeed a json-formatted ipynb file.\"\"\"\n",
    "    if is_valid_json(notebook):\n",
    "        return notebook\n",
    "        \n",
    "    return prompt(f\"\"\"\n",
    "Take the following text and extract the Jupyter \n",
    "notebook ipynb/json from it:\n",
    "\n",
    "{notebook}\n",
    "\n",
    "Make sure the output is in ipynb/json format. \n",
    "Respond only the JSON content.\n",
    "\"\"\").strip(\"```json\").strip(\"```python\").strip(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a5b4c-29d7-4ec7-b7e2-f232a695f960",
   "metadata": {},
   "source": [
    "## Context\n",
    "Here we provide some context to the language model. As gpt4 and claude have different APIs for providing system messages, we instead use this message to start the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeab283c-8453-4cd7-a0d8-0583c2bd64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are going to translate text from English to {target_language}. \n",
    "Do not modify any Python code. Do not translate it. Also do not translate strings in Python code.\n",
    "In case you receive markdown files or Jupyter notebooks in JSON format, leave the structure of the document as it is and just translate the English text to {target_language}.\n",
    "\n",
    "Confirm this with \"ok\".\n",
    "\"\"\"\n",
    "\n",
    "chat_history = [{\"role\": \"user\", \"content\": system_message}, {\"role\": \"assistant\", \"content\": \"ok\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eccf60-0cd3-4600-939a-7b94e00624db",
   "metadata": {},
   "source": [
    "## Generating the book\n",
    "Here we start generating the notebooks for the content listed in the table of contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5396923e-1698-4232-aae8-5efa906456bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_file(source_filename, target_filename):\n",
    "    # remove outputs from jupyter notebooks (because it might be too big otherwise)\n",
    "    if source_filename.endswith(\".ipynb\"): # notebook\n",
    "        # Load the notebook as a JSON object\n",
    "        with open(source_filename, 'r', encoding='utf-8') as f:\n",
    "            notebook_content = json.load(f)\n",
    "    \n",
    "        # Iterate through the cells and erase the outputs\n",
    "        for cell in notebook_content['cells']:\n",
    "            if cell['cell_type'] == 'code':\n",
    "                cell['outputs'] = []\n",
    "                cell['execution_count'] = None\n",
    "    \n",
    "        file_content = json.dumps(notebook_content, indent=1)\n",
    "    else:\n",
    "        with open(source_filename, 'r', encoding='utf-8') as f:\n",
    "            file_content = f.read()\n",
    "\n",
    "    # run LLM translation\n",
    "    translated_content = prompt_with_memory(file_content).strip(\"'\").strip('\"')\n",
    "\n",
    "    # copy code outputs from source to target file\n",
    "    if source_filename.endswith(\".ipynb\"): # notebook\n",
    "        with open(source_filename, 'r', encoding='utf-8') as f:\n",
    "            notebook_content = json.load(f)\n",
    "        \n",
    "        #print(translated_content)\n",
    "        \n",
    "        old_content = notebook_content\n",
    "        new_content = json.loads(translated_content)\n",
    "    \n",
    "        for o, n in zip(old_content['cells'], new_content['cells']):\n",
    "            if \"outputs\" in o.keys():\n",
    "                n['outputs'] = o['outputs']\n",
    "                n['execution_count'] = o['execution_count']\n",
    "    \n",
    "        translated_str = json.dumps(new_content, indent=1)\n",
    "    else:\n",
    "        translated_str = translated_content\n",
    "\n",
    "    # save result to target file\n",
    "    with open(target_filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(translated_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e97a9-af87-40ec-b5ce-2d33e7e9e112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating ../BioImageAnalysisNotebooks/docs/14_machine_learning_basics/supervised_machine_learning.ipynb to docs/14_machine_learning_basics/supervised_machine_learning.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/18a_deconvolution/introduction_deconvolution.ipynb to docs/18a_deconvolution/introduction_deconvolution.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/18_image_filtering/image_filtering.ipynb to docs/18_image_filtering/image_filtering.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/19_spatial_transforms/downsampling_with_denoising.ipynb to docs/19_spatial_transforms/downsampling_with_denoising.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/20h_segmentation_post_processing/mimicking_imagej_watershed.ipynb to docs/20h_segmentation_post_processing/mimicking_imagej_watershed.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/21_surface_processing/surface_vertex_classification.ipynb to docs/21_surface_processing/surface_vertex_classification.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/22_feature_extraction/distance_along_line.ipynb to docs/22_feature_extraction/distance_along_line.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/22_feature_extraction/statistics_with_simpleitk.ipynb to docs/22_feature_extraction/statistics_with_simpleitk.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/25_neighborhood_relationships_between_cells/06_mesh_with_distances.ipynb to docs/25_neighborhood_relationships_between_cells/06_mesh_with_distances.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/25_neighborhood_relationships_between_cells/statistics_of_neighbors.ipynb to docs/25_neighborhood_relationships_between_cells/statistics_of_neighbors.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/25_neighborhood_relationships_between_cells/touch_portion_explained.ipynb to docs/25_neighborhood_relationships_between_cells/touch_portion_explained.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/27_cell_classification/forest_statistics.ipynb to docs/27_cell_classification/forest_statistics.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/27_cell_classification/sklearn_object_classification.ipynb to docs/27_cell_classification/sklearn_object_classification.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/28_colocalization/counting_nuclei_multichannel.ipynb to docs/28_colocalization/counting_nuclei_multichannel.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/28_colocalization/differentiate_nuclei_intensity.ipynb to docs/28_colocalization/differentiate_nuclei_intensity.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/28_colocalization/distance-based_colocalization.ipynb to docs/28_colocalization/distance-based_colocalization.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/29_algorithm_validation/metrics_to_investigate_segmentation_quality.ipynb to docs/29_algorithm_validation/metrics_to_investigate_segmentation_quality.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/29_algorithm_validation/quantiative_comparison.ipynb to docs/29_algorithm_validation/quantiative_comparison.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/29_algorithm_validation/validate-spot-counting.ipynb to docs/29_algorithm_validation/validate-spot-counting.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/30_simulating_data/counting_cell_neighbors_in_tissues.ipynb to docs/30_simulating_data/counting_cell_neighbors_in_tissues.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/32_tiled_image_processing/tiled_object_measurements.ipynb to docs/32_tiled_image_processing/tiled_object_measurements.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/32_tiled_image_processing/tiling_images_naive_approach.ipynb to docs/32_tiled_image_processing/tiling_images_naive_approach.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/32_tiled_image_processing/tiling_images_with_overlap.ipynb to docs/32_tiled_image_processing/tiling_images_with_overlap.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/33_batch_processing/12_process_folders.ipynb to docs/33_batch_processing/12_process_folders.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/33_batch_processing/14_process_timelapse.ipynb to docs/33_batch_processing/14_process_timelapse.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/33_batch_processing/readme.md to docs/33_batch_processing/readme.md\n",
      "Translating ../BioImageAnalysisNotebooks/docs/33_batch_processing/run_on_all_hyperslices.ipynb to docs/33_batch_processing/run_on_all_hyperslices.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/34_timelapse_analysis/intensity_over_time.ipynb to docs/34_timelapse_analysis/intensity_over_time.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/34_timelapse_analysis/readme.md to docs/34_timelapse_analysis/readme.md\n",
      "Translating ../BioImageAnalysisNotebooks/docs/34_timelapse_analysis/tracking.ipynb to docs/34_timelapse_analysis/tracking.ipynb\n",
      "Error\n",
      "Translating ../BioImageAnalysisNotebooks/docs/35_parameter_optimization/label_image_optimizer.ipynb to docs/35_parameter_optimization/label_image_optimizer.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/35_parameter_optimization/membrane_segmentation.ipynb to docs/35_parameter_optimization/membrane_segmentation.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/35_parameter_optimization/optimization_basics.ipynb to docs/35_parameter_optimization/optimization_basics.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/35_parameter_optimization/readme.md to docs/35_parameter_optimization/readme.md\n",
      "Translating ../BioImageAnalysisNotebooks/docs/3ways/load_an_show_an_image.ipynb to docs/3ways/load_an_show_an_image.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/3ways/load_image_and_measure_shape_of_nuclei_in_3d.ipynb to docs/3ways/load_image_and_measure_shape_of_nuclei_in_3d.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/3ways/parametric_maps.ipynb to docs/3ways/parametric_maps.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/3ways/readme.md to docs/3ways/readme.md\n",
      "Translating ../BioImageAnalysisNotebooks/docs/3ways/resave_skimage_example_data.ipynb to docs/3ways/resave_skimage_example_data.ipynb\n",
      "Translating ../BioImageAnalysisNotebooks/docs/40a_sql/group_by.ipynb to docs/40a_sql/group_by.ipynb\n"
     ]
    }
   ],
   "source": [
    "memory_len = len(chat_history)\n",
    "for root, dirs, files in os.walk(source_dir):\n",
    "    for file in files:\n",
    "        if not \"-checkpoint\" in file and not \"Untitled\" in file and not \"_build\" in root and not \".git/\" in root and not \".git\\\\\" in root and not \"generator.ipynb\" in file:\n",
    "\n",
    "            source_file = os.path.join(root, file).replace(\"\\\\\", \"/\")\n",
    "            target_file = source_file.replace(source_dir, base_dir).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            # make sure target folder exists\n",
    "            directory = Path(target_file).parent\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "            if not os.path.exists(target_file): # avoid re-generating the same files\n",
    "                try:\n",
    "                    if file.endswith(\".md\") or file.endswith(\".ipynb\"):\n",
    "                        \n",
    "                        chat_history = chat_history[:memory_len]\n",
    "                        \n",
    "                        print(f\"Translating {source_file} to {target_file}\")\n",
    "                        translate_file(source_file, target_file)\n",
    "                    else:\n",
    "                        print(f\"Copying {source_file} to {target_file}\")\n",
    "                        shutil.copy(source_file, target_file)\n",
    "                except:\n",
    "                    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e21d0-e8af-4628-845f-d36434f3b517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7f540-3e34-4cd6-bdae-9fb7ab0a5b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
